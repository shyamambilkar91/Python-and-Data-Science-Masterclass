{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31554a20",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88516c",
   "metadata": {},
   "source": [
    "1. It is supervied Machine Learning algorithm\n",
    "2. Navie Bayes is one of the most powerful algorithm for classification based on **Baye's Theroem** with an independence among predictors.\n",
    "3. Naive Bayes model is easy to build and particularly useful in large data set.\n",
    "4. There are two parts of Naive Bayes:\n",
    "    1. Naive \n",
    "    2. Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed48530",
   "metadata": {},
   "source": [
    "## 1. Naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75719e81",
   "metadata": {},
   "source": [
    "1. The Naive Bayes classifier assumes that the presence of a feature in class is unrelated to any other feature.\n",
    "2. Even if these features depend on other or upon existing of other feature.\n",
    "3. All these features properties indendently contribute to the probability that a particular fruits is an apple or orange or banana and that is why it is known 'Naive'\n",
    "4. such as fruit is identify based on color, size, shape and test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68309c94",
   "metadata": {},
   "source": [
    "### 2. Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f369e59",
   "metadata": {},
   "source": [
    "1. It is called as Bayes because it depends on the Principle of Bayes Theroem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a2f83",
   "metadata": {},
   "source": [
    "### What is Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14a175",
   "metadata": {},
   "source": [
    "1. Bayes Theorem is also called as Bayes Rule or Bayes Low\n",
    "2. Bayes Theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event\n",
    "3. It depends on Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e88219",
   "metadata": {},
   "source": [
    "**Given Hypothesis [H] and evidenece E, Bayes Theorem states that the relationship between the probability of Hypothesis before getting the evidence P(H) and the Probability of the hypothesis after getting the evidence P(H|E)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f40c0d",
   "metadata": {},
   "source": [
    "### P(H|E) = P(E|H).P(H) / P(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a952baf",
   "metadata": {},
   "source": [
    "![](https://www.saedsayad.com/images/Bayes_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e265530d",
   "metadata": {},
   "source": [
    "### 1. Posterior Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434abe5",
   "metadata": {},
   "source": [
    "1. Probability of Hypothesis A on the observed even B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3329279",
   "metadata": {},
   "source": [
    "### 2. Marginal Probability P(x) | Predictor Prior Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dbfd1d",
   "metadata": {},
   "source": [
    "1. Probability of Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf9328",
   "metadata": {},
   "source": [
    "### 3. Likelihood Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a25591",
   "metadata": {},
   "source": [
    "1. Probability of evidence given that the probability of hypothesis is true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b372bd",
   "metadata": {},
   "source": [
    "### 4. Prior Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e5d47",
   "metadata": {},
   "source": [
    "1. Probability of hypothesis before observing the evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8b274",
   "metadata": {},
   "source": [
    "**Probability of the hypothesis before getting the evidence P(H) to the probability of the hypothesis after getting the evidence p(H|E) for this reason it is called as Prior Probability.\n",
    "while P(H|E) is called posterior probability. The factor that related with the two P(H|E) / P(E) is called Likelihood ratio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24590559",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602badb0",
   "metadata": {},
   "source": [
    "1. Suppoose consider We have a Deck of Cards, we wish to find out the **\"Probability of the card we picked at random to be a king given that it is face card\"**. According to Bayes Therom we can solve the Problem"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17e6d7d3",
   "metadata": {},
   "source": [
    "Deck of Cards\n",
    "\n",
    "Total Cards - 52\n",
    "Face Cards - 12\n",
    "KING = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2f80a",
   "metadata": {},
   "source": [
    "1. P(KING) which is 4/52 as there are 4 kings in a Deck of Cards\n",
    "2. P(FACE | KING) is equal to [1] as all the kings are face cards\n",
    "3. P(FACE) is equal ot 12/52 as there are 3 face cards is suit of 13 cards and there are 4 suits in total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf50348",
   "metadata": {},
   "source": [
    "**P(KING | FACE) = P(FACE | KING) * P(KING) / P(FACE)**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af58e921",
   "metadata": {},
   "source": [
    "P(KING) = 4/52 = 1/13\n",
    "P(FACE | KING) = 1\n",
    "P(FACE) = 12/52 = 3/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854445b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019723865877712033"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * (1/13) / 3/13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a4ae2",
   "metadata": {},
   "source": [
    "## Bayes Theroem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946a65b",
   "metadata": {},
   "source": [
    "Here we have Probability of\n",
    "\n",
    "P(A | B) = P(A intersection B) / P(B)\n",
    "    \n",
    "P(B | A) = P(B intersection A) / P(A)\n",
    "\n",
    "Now, join probability distribution Set A and B the probability, Now calculate the Probability\n",
    "\n",
    "P( A intersection B) = P(A | B) * P(A)\n",
    "                     = P(B | A) * P(B)\n",
    "                     = P(A | B)\n",
    "                     = P(B | A) * P(B) / P(A)\n",
    "            \n",
    "            \n",
    "Now, from this method, we get are final based theorem Proof, this equation to applies the probability of distribution. \n",
    "It has perticular deu interpretation in are where represented.\n",
    "If hypothesis H and B is represent as some observed evidence E in that case\n",
    "\n",
    "P (H | E) = P(E | H) * P(H) / P(E)\n",
    "\n",
    "Now, this refers the probability of hypothesis before getting the evidence P(E | E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af9de6",
   "metadata": {},
   "source": [
    "### Differnt types of Bayes Theroem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79005e47",
   "metadata": {},
   "source": [
    "1. Gaussian Naive Bayes\n",
    "2. Multinomial Naive Bayes\n",
    "3. Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb67f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
