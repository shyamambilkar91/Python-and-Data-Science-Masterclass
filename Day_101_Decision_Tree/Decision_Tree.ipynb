{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a05fe9a",
   "metadata": {},
   "source": [
    "# Decision_Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a48ad21",
   "metadata": {},
   "source": [
    "### 1. What is Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4be51",
   "metadata": {},
   "source": [
    "1. Decison Tree family of supervised Learning algorithm\n",
    "2. It can be used for classification and Regression\n",
    "3. Goal of Decision Tree is create a model that predict the value of variable\n",
    "4. Decision tree used tree representation to solve problem in which leaf nodes to class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ece47b5",
   "metadata": {},
   "source": [
    "### Defination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb80229",
   "metadata": {},
   "source": [
    "**A Decision Tree is supervised Machine learning algorithm which looks like an inverted tree, wherein each node representation of predictor variable(feature), link between the node represents the Decision each leaf node represent the outcome variable** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383f10f",
   "metadata": {},
   "source": [
    "### 2. Why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac5848b",
   "metadata": {},
   "source": [
    "1. Decision Tree is one of the powerful and most useful algorithm in Machine Learning\n",
    "2. Decision Tree can solved variety of Problems\n",
    "3. It is considered as most understanding algorithm\n",
    "4. It is easily interpreted\n",
    "5. It can be used both classification and Regression problms\n",
    "6. Constructing a Decision Tree is very quick process\n",
    "7. It uses only one feature per mode to split of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73996205",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f746c",
   "metadata": {},
   "source": [
    "![](https://www.xoriant.com/sites/default/files/uploads/2017/08/Decision-Trees-modified-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0d1e7e",
   "metadata": {},
   "source": [
    "### Decision Tree has Following Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50813215",
   "metadata": {},
   "source": [
    "1. Root Node:\n",
    "    1. Starting Point of Tree\n",
    "    2. First split Performed on this node\n",
    "2. Internal Node:\n",
    "    1. Each Internal Node represent the Decision Point (Prdictor Variable)\n",
    "3. Leaf / Terminal Nodes:\n",
    "    1. leaf node represents the final class of outcome Tree\n",
    "    2. Leaf node also called Terminal Node\n",
    "4. Branches:\n",
    "    1. Branches are connection of between nodes, represents using arrow\n",
    "    2. Each Branch represents the response as 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d4203",
   "metadata": {},
   "source": [
    "### How Decision Tree will works ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462d221",
   "metadata": {},
   "source": [
    "1. Decision Tree algorithm used three different steps:\n",
    "    1. Step 1:\n",
    "        1. Select Feature (Predictor Variable) that best classifies data into disired class\n",
    "        2. Assign all feature to the Root Node\n",
    "    2. Step 2:\n",
    "        1. Traverse down the Root Node, making relavant decision of each internal node\n",
    "        2. Each Internal node best classifies data\n",
    "    3. Step 3:\n",
    "        1. Repeat Step 1\n",
    "        2. Untill you assign all class to the input class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a3a22",
   "metadata": {},
   "source": [
    "### Assumption that we make while using Decision Tree ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36282c9c",
   "metadata": {},
   "source": [
    "1. In the Decision Tree, we consider all the datasets as Root\n",
    "2. Feature values are prefered to categorical, if the value contineous then convert it into descrete variable before building a machine learning model\n",
    "3. Based on Attributed values records are distributed recuresively\n",
    "4. We use statistical method for ordering attributed as Root Node or Internal Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6f538",
   "metadata": {},
   "source": [
    "### On the Basis of Multiple Algorithm Decision Tree Performs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5476c3",
   "metadata": {},
   "source": [
    "1. Logistic Regression - 75%\n",
    "2. Naive Bayes - 70%\n",
    "3. KNN - 75%\n",
    "4. Support Vector Machine - 77%\n",
    "5. Decision Tree - 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da32f4",
   "metadata": {},
   "source": [
    "### Build A Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df403",
   "metadata": {},
   "source": [
    "1. ID3 - Iterative Dichometer 3 algorithm is one of the most effective algorithm to build a decision Tree\n",
    "2. CART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2a478",
   "metadata": {},
   "source": [
    "# 1. ID3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e57b456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
