{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2a9d03",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e72b33d",
   "metadata": {},
   "source": [
    "## 1. Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447feeb",
   "metadata": {},
   "source": [
    "1. Precision is a measure of how accurate a model's positive prediction \n",
    "2. It is defined as the ratio of true positive prediction to the total number of positive prediction made by the model\n",
    "3. Precison tell us how many of the correctly predicted cases actually turned out to be positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc4b2b",
   "metadata": {},
   "source": [
    "### Precision = TP / FP + TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543427d3",
   "metadata": {},
   "source": [
    "**Note: Precision is useful matrix incase where False Positive is higher than concern than False Negative**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff598368",
   "metadata": {},
   "source": [
    "4. Precision is useful (important) matrix in music or video recommandations system, e-commerce, website etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8286d0ad",
   "metadata": {},
   "source": [
    "## 2. Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f7fca",
   "metadata": {},
   "source": [
    "1. Recall tell us how many of the Actual Positive cases we were able to predicted with our model.\n",
    "2. Recall measure the effectiveness of a classification model in identifying all relevant instances from a datasets.\n",
    "3. It is the ratio of number of true positive (TP) instances to the sum of true positive and False Negative (FN) instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ae1e0",
   "metadata": {},
   "source": [
    "### Recall = TP / TP + FN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4626d",
   "metadata": {},
   "source": [
    "**Note: Recall is important in medical cases where it dosent matter whether we raised a False alarm but the actual positive cases should not go undetected**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad10b65",
   "metadata": {},
   "source": [
    "## 3. F1- Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5778c011",
   "metadata": {},
   "source": [
    "1. F1-Score is used to evaluate overall performance of classfication model.\n",
    "2. It is hormonic mean of precision and recall\n",
    "3. We balance precision and recall with the F1-Score when a trade-off between minimizing False Positive and False Negative is necessory such Information retrival system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32268738",
   "metadata": {},
   "source": [
    "### F1-Score = 2 / (1 / Precision) + (1 / Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e557501",
   "metadata": {},
   "source": [
    "## 4. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783189f",
   "metadata": {},
   "source": [
    "1. Accuracy is used to measure the performance of the model. \n",
    "2. It is the ratio of Total number of instances to the total instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f388b21c",
   "metadata": {},
   "source": [
    "### Accuracy = TP + TN / TP + FP + FN + TN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d3583",
   "metadata": {},
   "source": [
    "# AUC - ROC CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b9aa6",
   "metadata": {},
   "source": [
    "1. The AUC curve, stands for Area Under Curve\n",
    "2. The ROC stands for Receiver Operating Charactristics\n",
    "3. It is used to graphical representation of the performance of binary classification model at various classification threshold\n",
    "4. In Machine learning, Performance measurement is an essential task\n",
    "5. When it comes classification problem, we count AUC-ROC Curve\n",
    "6. When we need to check or visualize the performance of multiclass classification problem, We use AUC and ROC\n",
    "7. AUC-ROC Curve is a performance measurement for the classification problem of varius threshold setting\n",
    "8. ROC is a probability curve and AOC represents the degree or measure of separability\n",
    "9. Higher the AUC, the better model predicting \n",
    "10. ROC Curve is plotted with TPR against the FPR, TPR is on Y-axis and FPR is on X-Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9c54f7",
   "metadata": {},
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20230410164437/AUC-ROC-Curve.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bb21e",
   "metadata": {},
   "source": [
    "### 1. TPR (True Positive Rate / Recall / Sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cadbbb",
   "metadata": {},
   "source": [
    "## TPR = TP / TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca5dee3",
   "metadata": {},
   "source": [
    "### 2. Specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e5366f",
   "metadata": {},
   "source": [
    "## Specificity = TN / TN + FP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f039451",
   "metadata": {},
   "source": [
    "### 3. FPR - False Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c405c259",
   "metadata": {},
   "source": [
    "### FPR = 1 - specificity [FP / FP + TN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef700ef",
   "metadata": {},
   "source": [
    "11. AUC Near to the 1 [100] which means it has a good measurement of separability\n",
    "12. A poor model has AUC near to the 0 which means it is worst measure of separability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8dcbc",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:1200/1*Bgc9QOjhnL70g2SQxyj6hQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a59a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
